{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vision2_0301_1_vision1train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOGXJaSV9IWMfNh7/H2P423",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HYUNMIN-HWANG/Colab/blob/main/DACON_vision2/vision2_0301_1_vision1train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QZu2YOy2j42",
        "outputId": "3fa11b13-dedf-4422-c998-41a168ba81ee"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('./MyDrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at ./MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLOmKF2P3pos"
      },
      "source": [
        "# vision1에 나온 알파벳들을 훈련시켜보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsDyq6TL2_bY"
      },
      "source": [
        "# warnings.filterwarnings(\"ignore\")\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\r\n",
        "from tensorflow.keras.models import Sequential, load_model\r\n",
        "from tensorflow.keras.layers import *\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras import optimizers\r\n",
        "import cv2\r\n",
        "import gc\r\n",
        "from keras import backend as bek\r\n",
        "from sklearn.model_selection import train_test_split, KFold\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\r\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\r\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\r\n",
        "\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN3GiQsH3HG8",
        "outputId": "88a92754-3953-4079-c72c-4249e451608b"
      },
      "source": [
        "train = pd.read_csv('/content/MyDrive/MyDrive/AIA/DACON_vision1/train.csv')\r\n",
        "print(train.shape)  # (2048, 787)\r\n",
        "\r\n",
        "submission = pd.read_csv('/content/MyDrive/MyDrive/AIA/DACON_vision1/submission.csv')\r\n",
        "print(submission.shape) # (20480, 2)\r\n",
        "\r\n",
        "test = pd.read_csv('/content/MyDrive/MyDrive/AIA/DACON_vision1/test.csv')\r\n",
        "print(test.shape)   # (20480, 786)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2048, 787)\n",
            "(20480, 2)\n",
            "(20480, 786)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VCSzsIks96o",
        "outputId": "0a94e4dd-d046-408e-c345-871900c428be"
      },
      "source": [
        "x = np.load('/content/MyDrive/MyDrive/Colab/DACON_vision2/npy/vision1_x28.npy')\r\n",
        "print(x.shape)\r\n",
        "y = np.load('/content/MyDrive/MyDrive/Colab/DACON_vision2/npy/vision1_y28.npy')\r\n",
        "print(y.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(22528, 56, 56, 3)\n",
            "(22528,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LW0ABclLVX0"
      },
      "source": [
        "# modeling\r\n",
        "def modeling() :\r\n",
        "    model = Sequential()\r\n",
        "    model.add(Conv2D(128, 3, activation='selu', padding='same', input_shape=(xx_train.shape[1], xx_train.shape[2], xx_train.shape[3])))\r\n",
        "    model.add(BatchNormalization()) \r\n",
        "    model.add(Conv2D(128, 3, activation='relu', padding='same'))\r\n",
        "    model.add(BatchNormalization()) \r\n",
        "    model.add(MaxPooling2D(2,2))\r\n",
        "\r\n",
        "    model.add(Conv2D(32, 3, activation='selu', padding='same'))\r\n",
        "    model.add(BatchNormalization()) \r\n",
        "    model.add(Conv2D(32, 2, activation='elu', padding='same'))\r\n",
        "    model.add(BatchNormalization()) \r\n",
        "    model.add(MaxPooling2D(2,2))\r\n",
        "\r\n",
        "    model.add(Conv2D(64, 3, activation='elu', padding='same'))\r\n",
        "    model.add(BatchNormalization()) \r\n",
        "    model.add(Conv2D(64, 2, activation='elu', padding='same'))\r\n",
        "    model.add(BatchNormalization()) \r\n",
        "    model.add(MaxPooling2D(2,2))\r\n",
        "\r\n",
        "    model.add(Flatten())\r\n",
        "\r\n",
        "    model.add(Dense(256, activation='selu'))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "    model.add(Dense(128, activation='selu'))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "    model.add(Dense(26, activation='softmax'))\r\n",
        "\r\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['acc'])\r\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcxIxOf1IFoi",
        "outputId": "f101b9a7-bec5-4421-e801-aad1df8a2641"
      },
      "source": [
        "kf_times = 8\r\n",
        "kf = KFold(n_splits=kf_times, shuffle=True, random_state=42)\r\n",
        "\r\n",
        "idg = ImageDataGenerator(height_shift_range=(-1,1), \r\n",
        "                        width_shift_range=(-1,1),\r\n",
        "                        rotation_range=120,\r\n",
        "                        fill_mode='nearest'\r\n",
        "                        )\r\n",
        "idg2 = ImageDataGenerator()\r\n",
        "\r\n",
        "kf_n = 1\r\n",
        "loss_hist = []\r\n",
        "acc_hist = []\r\n",
        "for train_index, test_index in kf.split(x, y) :\r\n",
        "    print(\"\\n** Kfold %d 번째 실행 중 **\" % kf_n)\r\n",
        "    xx_train, xx_test = x[train_index], x[test_index]\r\n",
        "    yy_train, yy_test = y[train_index], y[test_index]\r\n",
        "\r\n",
        "    xx_train, xx_valid, yy_train, yy_valid = train_test_split(xx_train, yy_train, train_size=0.9, shuffle=True, random_state=42)\r\n",
        "    print(xx_train.shape, xx_test.shape, xx_valid.shape)    # (16219, 56, 56, 3) (4506, 56, 56, 3) (1803, 56, 56, 3)\r\n",
        "    print(yy_train.shape, yy_test.shape, yy_valid.shape)    # (16219,) (4506,) (1803,)\r\n",
        "\r\n",
        "    train_generator = idg.flow(xx_train, yy_train, batch_size=16)\r\n",
        "    test_generator = idg2.flow(xx_test, yy_test, batch_size=16)\r\n",
        "    valid_generator = idg2.flow(xx_valid, yy_valid)\r\n",
        "\r\n",
        "    model = modeling()\r\n",
        "\r\n",
        "    path = '/content/MyDrive/MyDrive/Colab/DACON_vision2/cp/vision_0301_1_vison1_{val_loss:.4f}.hdf5'\r\n",
        "    cp = ModelCheckpoint(path, monitor='val_loss', save_best_only=True, mode='min')\r\n",
        "    rl = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, mode='min')\r\n",
        "    es = EarlyStopping(monitor='val_loss', patience=20, mode='min')\r\n",
        "\r\n",
        "    model.fit_generator(train_generator, epochs=500, validation_data=valid_generator, callbacks=[cp, rl, es])\r\n",
        "\r\n",
        "    loss, acc = model.evaluate(test_generator)\r\n",
        "    print(\"loss : \", loss)\r\n",
        "    print(\"acc : \", acc)\r\n",
        "\r\n",
        "    loss_hist.append(loss)\r\n",
        "    acc_hist.append(acc)\r\n",
        "\r\n",
        "    kf_n +=1\r\n",
        "\r\n",
        "print(\"mean loss : \", sum(loss_hist)/kf_times)\r\n",
        "print(\"mean acc : \", sum(acc_hist)/kf_times)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "** Kfold 1 번째 실행 중 **\n",
            "(17740, 56, 56, 3) (2816, 56, 56, 3) (1972, 56, 56, 3)\n",
            "(17740,) (2816,) (1972,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "1109/1109 [==============================] - 24s 21ms/step - loss: 2.3984 - acc: 0.3093 - val_loss: 1.6198 - val_acc: 0.5193\n",
            "Epoch 2/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 1.4072 - acc: 0.5613 - val_loss: 1.1043 - val_acc: 0.6537\n",
            "Epoch 3/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 1.1948 - acc: 0.6223 - val_loss: 0.8450 - val_acc: 0.7368\n",
            "Epoch 4/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 1.0819 - acc: 0.6558 - val_loss: 0.8065 - val_acc: 0.7333\n",
            "Epoch 5/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 1.0040 - acc: 0.6855 - val_loss: 0.8117 - val_acc: 0.7378\n",
            "Epoch 6/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.9608 - acc: 0.6972 - val_loss: 0.7402 - val_acc: 0.7703\n",
            "Epoch 7/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.9338 - acc: 0.7042 - val_loss: 0.6589 - val_acc: 0.7911\n",
            "Epoch 8/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.8931 - acc: 0.7154 - val_loss: 0.6788 - val_acc: 0.7896\n",
            "Epoch 9/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.8747 - acc: 0.7217 - val_loss: 0.6662 - val_acc: 0.7850\n",
            "Epoch 10/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.8286 - acc: 0.7398 - val_loss: 0.6563 - val_acc: 0.7916\n",
            "Epoch 11/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.8131 - acc: 0.7430 - val_loss: 0.6161 - val_acc: 0.7946\n",
            "Epoch 12/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.7616 - acc: 0.7569 - val_loss: 0.6485 - val_acc: 0.8088\n",
            "Epoch 13/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.7647 - acc: 0.7537 - val_loss: 0.5593 - val_acc: 0.8261\n",
            "Epoch 14/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.7506 - acc: 0.7654 - val_loss: 0.5758 - val_acc: 0.8200\n",
            "Epoch 15/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.7290 - acc: 0.7662 - val_loss: 0.6012 - val_acc: 0.8027\n",
            "Epoch 16/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.7442 - acc: 0.7601 - val_loss: 0.5887 - val_acc: 0.8119\n",
            "Epoch 17/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.7277 - acc: 0.7663 - val_loss: 0.5039 - val_acc: 0.8347\n",
            "Epoch 18/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.7091 - acc: 0.7770 - val_loss: 0.5107 - val_acc: 0.8332\n",
            "Epoch 19/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.6657 - acc: 0.7815 - val_loss: 0.5932 - val_acc: 0.8078\n",
            "Epoch 20/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6772 - acc: 0.7833 - val_loss: 0.5116 - val_acc: 0.8367\n",
            "Epoch 21/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6778 - acc: 0.7817 - val_loss: 0.5063 - val_acc: 0.8398\n",
            "Epoch 22/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6586 - acc: 0.7857 - val_loss: 0.4687 - val_acc: 0.8463\n",
            "Epoch 23/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6364 - acc: 0.7915 - val_loss: 0.5053 - val_acc: 0.8296\n",
            "Epoch 24/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6264 - acc: 0.8019 - val_loss: 0.5432 - val_acc: 0.8322\n",
            "Epoch 25/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6418 - acc: 0.7895 - val_loss: 0.4772 - val_acc: 0.8438\n",
            "Epoch 26/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6387 - acc: 0.7892 - val_loss: 0.5212 - val_acc: 0.8382\n",
            "Epoch 27/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6103 - acc: 0.8003 - val_loss: 0.4433 - val_acc: 0.8590\n",
            "Epoch 28/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6134 - acc: 0.7989 - val_loss: 0.4826 - val_acc: 0.8469\n",
            "Epoch 29/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5960 - acc: 0.8049 - val_loss: 0.4836 - val_acc: 0.8469\n",
            "Epoch 30/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5981 - acc: 0.8011 - val_loss: 0.5000 - val_acc: 0.8479\n",
            "Epoch 31/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5940 - acc: 0.8050 - val_loss: 0.4920 - val_acc: 0.8489\n",
            "Epoch 32/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5875 - acc: 0.8110 - val_loss: 0.5179 - val_acc: 0.8448\n",
            "Epoch 33/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5852 - acc: 0.8099 - val_loss: 0.4491 - val_acc: 0.8514\n",
            "Epoch 34/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5832 - acc: 0.8045 - val_loss: 0.4893 - val_acc: 0.8362\n",
            "Epoch 35/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5757 - acc: 0.8112 - val_loss: 0.4880 - val_acc: 0.8418\n",
            "Epoch 36/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5783 - acc: 0.8066 - val_loss: 0.4777 - val_acc: 0.8387\n",
            "Epoch 37/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5723 - acc: 0.8102 - val_loss: 0.4651 - val_acc: 0.8443\n",
            "Epoch 38/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5393 - acc: 0.8236 - val_loss: 0.4162 - val_acc: 0.8585\n",
            "Epoch 39/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4904 - acc: 0.8408 - val_loss: 0.4060 - val_acc: 0.8651\n",
            "Epoch 40/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4693 - acc: 0.8442 - val_loss: 0.3966 - val_acc: 0.8682\n",
            "Epoch 41/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4762 - acc: 0.8388 - val_loss: 0.3957 - val_acc: 0.8707\n",
            "Epoch 42/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4720 - acc: 0.8402 - val_loss: 0.3906 - val_acc: 0.8692\n",
            "Epoch 43/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4706 - acc: 0.8456 - val_loss: 0.3860 - val_acc: 0.8682\n",
            "Epoch 44/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4488 - acc: 0.8468 - val_loss: 0.3835 - val_acc: 0.8722\n",
            "Epoch 45/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4528 - acc: 0.8508 - val_loss: 0.3865 - val_acc: 0.8717\n",
            "Epoch 46/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4548 - acc: 0.8481 - val_loss: 0.3820 - val_acc: 0.8758\n",
            "Epoch 47/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4437 - acc: 0.8544 - val_loss: 0.3728 - val_acc: 0.8722\n",
            "Epoch 48/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4603 - acc: 0.8474 - val_loss: 0.3802 - val_acc: 0.8758\n",
            "Epoch 49/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4345 - acc: 0.8550 - val_loss: 0.3898 - val_acc: 0.8727\n",
            "Epoch 50/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4325 - acc: 0.8567 - val_loss: 0.3809 - val_acc: 0.8717\n",
            "Epoch 51/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4292 - acc: 0.8549 - val_loss: 0.3768 - val_acc: 0.8773\n",
            "Epoch 52/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4216 - acc: 0.8557 - val_loss: 0.3738 - val_acc: 0.8742\n",
            "Epoch 53/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4314 - acc: 0.8517 - val_loss: 0.3759 - val_acc: 0.8793\n",
            "Epoch 54/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4244 - acc: 0.8549 - val_loss: 0.3790 - val_acc: 0.8747\n",
            "Epoch 55/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4278 - acc: 0.8551 - val_loss: 0.3762 - val_acc: 0.8768\n",
            "Epoch 56/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4310 - acc: 0.8521 - val_loss: 0.3696 - val_acc: 0.8824\n",
            "Epoch 57/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4136 - acc: 0.8581 - val_loss: 0.3754 - val_acc: 0.8783\n",
            "Epoch 58/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4259 - acc: 0.8571 - val_loss: 0.3773 - val_acc: 0.8793\n",
            "Epoch 59/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4191 - acc: 0.8613 - val_loss: 0.3755 - val_acc: 0.8773\n",
            "Epoch 60/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4064 - acc: 0.8621 - val_loss: 0.3782 - val_acc: 0.8793\n",
            "Epoch 61/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4161 - acc: 0.8600 - val_loss: 0.3790 - val_acc: 0.8783\n",
            "Epoch 62/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4127 - acc: 0.8629 - val_loss: 0.3844 - val_acc: 0.8768\n",
            "Epoch 63/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4006 - acc: 0.8648 - val_loss: 0.3856 - val_acc: 0.8808\n",
            "Epoch 64/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4195 - acc: 0.8562 - val_loss: 0.3851 - val_acc: 0.8758\n",
            "Epoch 65/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4164 - acc: 0.8581 - val_loss: 0.3757 - val_acc: 0.8793\n",
            "Epoch 66/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4143 - acc: 0.8615 - val_loss: 0.3637 - val_acc: 0.8803\n",
            "Epoch 67/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3991 - acc: 0.8638 - val_loss: 0.3630 - val_acc: 0.8839\n",
            "Epoch 68/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3999 - acc: 0.8639 - val_loss: 0.3662 - val_acc: 0.8808\n",
            "Epoch 69/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3939 - acc: 0.8633 - val_loss: 0.3687 - val_acc: 0.8778\n",
            "Epoch 70/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3995 - acc: 0.8630 - val_loss: 0.3597 - val_acc: 0.8854\n",
            "Epoch 71/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4067 - acc: 0.8599 - val_loss: 0.3707 - val_acc: 0.8869\n",
            "Epoch 72/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3961 - acc: 0.8663 - val_loss: 0.3733 - val_acc: 0.8829\n",
            "Epoch 73/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3942 - acc: 0.8696 - val_loss: 0.3464 - val_acc: 0.8920\n",
            "Epoch 74/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3864 - acc: 0.8689 - val_loss: 0.3695 - val_acc: 0.8844\n",
            "Epoch 75/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4013 - acc: 0.8674 - val_loss: 0.3625 - val_acc: 0.8834\n",
            "Epoch 76/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3881 - acc: 0.8677 - val_loss: 0.3649 - val_acc: 0.8813\n",
            "Epoch 77/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3908 - acc: 0.8666 - val_loss: 0.3682 - val_acc: 0.8803\n",
            "Epoch 78/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3815 - acc: 0.8718 - val_loss: 0.3700 - val_acc: 0.8758\n",
            "Epoch 79/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4058 - acc: 0.8595 - val_loss: 0.3734 - val_acc: 0.8813\n",
            "Epoch 80/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3788 - acc: 0.8704 - val_loss: 0.3582 - val_acc: 0.8834\n",
            "Epoch 81/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3895 - acc: 0.8708 - val_loss: 0.3628 - val_acc: 0.8824\n",
            "Epoch 82/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3747 - acc: 0.8733 - val_loss: 0.3681 - val_acc: 0.8834\n",
            "Epoch 83/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3894 - acc: 0.8671 - val_loss: 0.3667 - val_acc: 0.8859\n",
            "Epoch 84/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3733 - acc: 0.8718 - val_loss: 0.3616 - val_acc: 0.8839\n",
            "Epoch 85/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3637 - acc: 0.8761 - val_loss: 0.3592 - val_acc: 0.8834\n",
            "Epoch 86/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3586 - acc: 0.8723 - val_loss: 0.3572 - val_acc: 0.8859\n",
            "Epoch 87/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3678 - acc: 0.8756 - val_loss: 0.3592 - val_acc: 0.8849\n",
            "Epoch 88/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3571 - acc: 0.8762 - val_loss: 0.3534 - val_acc: 0.8869\n",
            "Epoch 89/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3584 - acc: 0.8806 - val_loss: 0.3541 - val_acc: 0.8859\n",
            "Epoch 90/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3613 - acc: 0.8773 - val_loss: 0.3552 - val_acc: 0.8859\n",
            "Epoch 91/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3546 - acc: 0.8789 - val_loss: 0.3546 - val_acc: 0.8854\n",
            "Epoch 92/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3562 - acc: 0.8752 - val_loss: 0.3516 - val_acc: 0.8849\n",
            "Epoch 93/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3698 - acc: 0.8756 - val_loss: 0.3551 - val_acc: 0.8854\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 0.3481 - acc: 0.8874\n",
            "loss :  0.3480527400970459\n",
            "acc :  0.8874289989471436\n",
            "\n",
            "** Kfold 2 번째 실행 중 **\n",
            "(17740, 56, 56, 3) (2816, 56, 56, 3) (1972, 56, 56, 3)\n",
            "(17740,) (2816,) (1972,)\n",
            "Epoch 1/500\n",
            "1109/1109 [==============================] - 24s 20ms/step - loss: 2.4988 - acc: 0.2865 - val_loss: 1.7760 - val_acc: 0.5076\n",
            "Epoch 2/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 1.4070 - acc: 0.5635 - val_loss: 0.9970 - val_acc: 0.7003\n",
            "Epoch 3/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 1.2120 - acc: 0.6207 - val_loss: 0.9343 - val_acc: 0.7175\n",
            "Epoch 4/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 1.0908 - acc: 0.6452 - val_loss: 0.9460 - val_acc: 0.7008\n",
            "Epoch 5/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 1.0274 - acc: 0.6808 - val_loss: 0.8247 - val_acc: 0.7394\n",
            "Epoch 6/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.9638 - acc: 0.6957 - val_loss: 0.7188 - val_acc: 0.7733\n",
            "Epoch 7/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.9233 - acc: 0.7089 - val_loss: 0.6983 - val_acc: 0.7698\n",
            "Epoch 8/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.8747 - acc: 0.7236 - val_loss: 0.6849 - val_acc: 0.7850\n",
            "Epoch 9/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.8648 - acc: 0.7263 - val_loss: 0.7065 - val_acc: 0.7860\n",
            "Epoch 10/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.8249 - acc: 0.7409 - val_loss: 0.7509 - val_acc: 0.7799\n",
            "Epoch 11/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.8204 - acc: 0.7378 - val_loss: 0.5582 - val_acc: 0.8256\n",
            "Epoch 12/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.7908 - acc: 0.7482 - val_loss: 0.5973 - val_acc: 0.8038\n",
            "Epoch 13/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.7798 - acc: 0.7498 - val_loss: 0.5801 - val_acc: 0.8149\n",
            "Epoch 14/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.7747 - acc: 0.7544 - val_loss: 0.6164 - val_acc: 0.8048\n",
            "Epoch 15/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.7463 - acc: 0.7640 - val_loss: 0.6291 - val_acc: 0.8103\n",
            "Epoch 16/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.7379 - acc: 0.7678 - val_loss: 0.6407 - val_acc: 0.8022\n",
            "Epoch 17/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.7195 - acc: 0.7641 - val_loss: 0.6940 - val_acc: 0.8078\n",
            "Epoch 18/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.7016 - acc: 0.7804 - val_loss: 0.5550 - val_acc: 0.8190\n",
            "Epoch 19/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6706 - acc: 0.7862 - val_loss: 0.5597 - val_acc: 0.8256\n",
            "Epoch 20/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6708 - acc: 0.7856 - val_loss: 0.5373 - val_acc: 0.8271\n",
            "Epoch 21/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6638 - acc: 0.7814 - val_loss: 0.5207 - val_acc: 0.8311\n",
            "Epoch 22/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6483 - acc: 0.7905 - val_loss: 0.6002 - val_acc: 0.8139\n",
            "Epoch 23/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6672 - acc: 0.7865 - val_loss: 0.5394 - val_acc: 0.8281\n",
            "Epoch 24/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.6281 - acc: 0.7924 - val_loss: 0.5650 - val_acc: 0.8235\n",
            "Epoch 25/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6298 - acc: 0.7969 - val_loss: 0.5619 - val_acc: 0.8220\n",
            "Epoch 26/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6261 - acc: 0.7912 - val_loss: 0.5014 - val_acc: 0.8403\n",
            "Epoch 27/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6294 - acc: 0.7961 - val_loss: 0.5324 - val_acc: 0.8332\n",
            "Epoch 28/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6173 - acc: 0.8007 - val_loss: 0.6431 - val_acc: 0.8007\n",
            "Epoch 29/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6142 - acc: 0.8007 - val_loss: 0.5457 - val_acc: 0.8200\n",
            "Epoch 30/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6002 - acc: 0.8035 - val_loss: 0.5132 - val_acc: 0.8276\n",
            "Epoch 31/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5878 - acc: 0.8111 - val_loss: 0.5117 - val_acc: 0.8311\n",
            "Epoch 32/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5939 - acc: 0.8014 - val_loss: 0.5054 - val_acc: 0.8332\n",
            "Epoch 33/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5719 - acc: 0.8091 - val_loss: 0.5104 - val_acc: 0.8367\n",
            "Epoch 34/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5763 - acc: 0.8143 - val_loss: 0.5126 - val_acc: 0.8428\n",
            "Epoch 35/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5672 - acc: 0.8155 - val_loss: 0.4985 - val_acc: 0.8413\n",
            "Epoch 36/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5782 - acc: 0.8134 - val_loss: 0.5119 - val_acc: 0.8382\n",
            "Epoch 37/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5702 - acc: 0.8105 - val_loss: 0.5193 - val_acc: 0.8306\n",
            "Epoch 38/500\n",
            "1109/1109 [==============================] - 23s 21ms/step - loss: 0.5423 - acc: 0.8201 - val_loss: 0.5007 - val_acc: 0.8296\n",
            "Epoch 39/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5393 - acc: 0.8174 - val_loss: 0.4649 - val_acc: 0.8560\n",
            "Epoch 40/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5635 - acc: 0.8195 - val_loss: 0.4754 - val_acc: 0.8408\n",
            "Epoch 41/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5581 - acc: 0.8153 - val_loss: 0.4697 - val_acc: 0.8504\n",
            "Epoch 42/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5465 - acc: 0.8202 - val_loss: 0.4670 - val_acc: 0.8453\n",
            "Epoch 43/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5443 - acc: 0.8190 - val_loss: 0.4625 - val_acc: 0.8529\n",
            "Epoch 44/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5404 - acc: 0.8217 - val_loss: 0.4936 - val_acc: 0.8403\n",
            "Epoch 45/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5270 - acc: 0.8279 - val_loss: 0.4847 - val_acc: 0.8529\n",
            "Epoch 46/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5482 - acc: 0.8209 - val_loss: 0.4735 - val_acc: 0.8550\n",
            "Epoch 47/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5205 - acc: 0.8251 - val_loss: 0.4567 - val_acc: 0.8565\n",
            "Epoch 48/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5121 - acc: 0.8291 - val_loss: 0.4912 - val_acc: 0.8398\n",
            "Epoch 49/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5151 - acc: 0.8343 - val_loss: 0.4526 - val_acc: 0.8504\n",
            "Epoch 50/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5219 - acc: 0.8301 - val_loss: 0.4916 - val_acc: 0.8453\n",
            "Epoch 51/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5041 - acc: 0.8333 - val_loss: 0.4818 - val_acc: 0.8489\n",
            "Epoch 52/500\n",
            "1109/1109 [==============================] - 23s 21ms/step - loss: 0.4873 - acc: 0.8411 - val_loss: 0.4566 - val_acc: 0.8555\n",
            "Epoch 53/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4934 - acc: 0.8358 - val_loss: 0.4345 - val_acc: 0.8626\n",
            "Epoch 54/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4958 - acc: 0.8349 - val_loss: 0.4208 - val_acc: 0.8626\n",
            "Epoch 55/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4886 - acc: 0.8406 - val_loss: 0.4569 - val_acc: 0.8540\n",
            "Epoch 56/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4965 - acc: 0.8314 - val_loss: 0.4022 - val_acc: 0.8707\n",
            "Epoch 57/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4814 - acc: 0.8395 - val_loss: 0.4143 - val_acc: 0.8631\n",
            "Epoch 58/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4824 - acc: 0.8391 - val_loss: 0.4693 - val_acc: 0.8555\n",
            "Epoch 59/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4818 - acc: 0.8388 - val_loss: 0.4436 - val_acc: 0.8570\n",
            "Epoch 60/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4867 - acc: 0.8411 - val_loss: 0.4559 - val_acc: 0.8499\n",
            "Epoch 61/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4716 - acc: 0.8419 - val_loss: 0.4547 - val_acc: 0.8565\n",
            "Epoch 62/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5028 - acc: 0.8349 - val_loss: 0.4407 - val_acc: 0.8605\n",
            "Epoch 63/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4700 - acc: 0.8397 - val_loss: 0.4405 - val_acc: 0.8585\n",
            "Epoch 64/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4841 - acc: 0.8356 - val_loss: 0.4348 - val_acc: 0.8631\n",
            "Epoch 65/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4484 - acc: 0.8470 - val_loss: 0.4068 - val_acc: 0.8661\n",
            "Epoch 66/500\n",
            "1109/1109 [==============================] - 23s 21ms/step - loss: 0.4818 - acc: 0.8403 - val_loss: 0.4418 - val_acc: 0.8585\n",
            "Epoch 67/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4352 - acc: 0.8551 - val_loss: 0.3876 - val_acc: 0.8788\n",
            "Epoch 68/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4118 - acc: 0.8608 - val_loss: 0.3830 - val_acc: 0.8798\n",
            "Epoch 69/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3892 - acc: 0.8688 - val_loss: 0.3882 - val_acc: 0.8798\n",
            "Epoch 70/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3921 - acc: 0.8660 - val_loss: 0.3820 - val_acc: 0.8758\n",
            "Epoch 71/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3901 - acc: 0.8661 - val_loss: 0.3681 - val_acc: 0.8818\n",
            "Epoch 72/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3934 - acc: 0.8644 - val_loss: 0.3997 - val_acc: 0.8818\n",
            "Epoch 73/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3903 - acc: 0.8689 - val_loss: 0.3786 - val_acc: 0.8808\n",
            "Epoch 74/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3760 - acc: 0.8704 - val_loss: 0.3701 - val_acc: 0.8844\n",
            "Epoch 75/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3710 - acc: 0.8749 - val_loss: 0.3731 - val_acc: 0.8834\n",
            "Epoch 76/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3648 - acc: 0.8742 - val_loss: 0.3749 - val_acc: 0.8803\n",
            "Epoch 77/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3741 - acc: 0.8750 - val_loss: 0.3729 - val_acc: 0.8813\n",
            "Epoch 78/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3775 - acc: 0.8696 - val_loss: 0.3669 - val_acc: 0.8874\n",
            "Epoch 79/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3689 - acc: 0.8731 - val_loss: 0.3710 - val_acc: 0.8854\n",
            "Epoch 80/500\n",
            "1109/1109 [==============================] - 23s 21ms/step - loss: 0.3762 - acc: 0.8723 - val_loss: 0.3712 - val_acc: 0.8798\n",
            "Epoch 81/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3693 - acc: 0.8751 - val_loss: 0.3801 - val_acc: 0.8818\n",
            "Epoch 82/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3626 - acc: 0.8756 - val_loss: 0.3812 - val_acc: 0.8808\n",
            "Epoch 83/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3578 - acc: 0.8739 - val_loss: 0.3669 - val_acc: 0.8854\n",
            "Epoch 84/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3638 - acc: 0.8771 - val_loss: 0.3657 - val_acc: 0.8793\n",
            "Epoch 85/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3557 - acc: 0.8798 - val_loss: 0.3808 - val_acc: 0.8793\n",
            "Epoch 86/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.3725 - acc: 0.8737 - val_loss: 0.3720 - val_acc: 0.8834\n",
            "Epoch 87/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.3436 - acc: 0.8811 - val_loss: 0.3783 - val_acc: 0.8818\n",
            "Epoch 88/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3467 - acc: 0.8796 - val_loss: 0.3822 - val_acc: 0.8839\n",
            "Epoch 89/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3451 - acc: 0.8781 - val_loss: 0.3804 - val_acc: 0.8818\n",
            "Epoch 90/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3367 - acc: 0.8847 - val_loss: 0.3680 - val_acc: 0.8834\n",
            "Epoch 91/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3433 - acc: 0.8817 - val_loss: 0.3796 - val_acc: 0.8864\n",
            "Epoch 92/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3499 - acc: 0.8798 - val_loss: 0.3669 - val_acc: 0.8818\n",
            "Epoch 93/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3577 - acc: 0.8766 - val_loss: 0.3838 - val_acc: 0.8798\n",
            "Epoch 94/500\n",
            "1109/1109 [==============================] - 23s 21ms/step - loss: 0.3431 - acc: 0.8797 - val_loss: 0.3694 - val_acc: 0.8803\n",
            "Epoch 95/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3443 - acc: 0.8803 - val_loss: 0.3750 - val_acc: 0.8798\n",
            "Epoch 96/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3389 - acc: 0.8777 - val_loss: 0.3752 - val_acc: 0.8798\n",
            "Epoch 97/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3286 - acc: 0.8864 - val_loss: 0.3743 - val_acc: 0.8808\n",
            "Epoch 98/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3288 - acc: 0.8875 - val_loss: 0.3746 - val_acc: 0.8839\n",
            "Epoch 99/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3396 - acc: 0.8794 - val_loss: 0.3716 - val_acc: 0.8844\n",
            "Epoch 100/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3332 - acc: 0.8887 - val_loss: 0.3731 - val_acc: 0.8803\n",
            "Epoch 101/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3355 - acc: 0.8836 - val_loss: 0.3744 - val_acc: 0.8793\n",
            "Epoch 102/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3306 - acc: 0.8847 - val_loss: 0.3769 - val_acc: 0.8778\n",
            "Epoch 103/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.3381 - acc: 0.8846 - val_loss: 0.3732 - val_acc: 0.8778\n",
            "Epoch 104/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.3245 - acc: 0.8916 - val_loss: 0.3758 - val_acc: 0.8798\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 0.3712 - acc: 0.8807\n",
            "loss :  0.3711585998535156\n",
            "acc :  0.8806818127632141\n",
            "\n",
            "** Kfold 3 번째 실행 중 **\n",
            "(17740, 56, 56, 3) (2816, 56, 56, 3) (1972, 56, 56, 3)\n",
            "(17740,) (2816,) (1972,)\n",
            "Epoch 1/500\n",
            "1109/1109 [==============================] - 24s 21ms/step - loss: 2.3951 - acc: 0.3136 - val_loss: 1.4151 - val_acc: 0.5943\n",
            "Epoch 2/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 1.3608 - acc: 0.5761 - val_loss: 1.0545 - val_acc: 0.6749\n",
            "Epoch 3/500\n",
            "1109/1109 [==============================] - 23s 21ms/step - loss: 1.1953 - acc: 0.6233 - val_loss: 0.9818 - val_acc: 0.6993\n",
            "Epoch 4/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 1.0610 - acc: 0.6633 - val_loss: 0.8142 - val_acc: 0.7444\n",
            "Epoch 5/500\n",
            "1109/1109 [==============================] - 23s 21ms/step - loss: 0.9966 - acc: 0.6904 - val_loss: 0.7712 - val_acc: 0.7546\n",
            "Epoch 6/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.9452 - acc: 0.7000 - val_loss: 0.7195 - val_acc: 0.7637\n",
            "Epoch 7/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.9184 - acc: 0.7025 - val_loss: 0.7291 - val_acc: 0.7647\n",
            "Epoch 8/500\n",
            "1109/1109 [==============================] - 23s 21ms/step - loss: 0.8670 - acc: 0.7255 - val_loss: 0.6693 - val_acc: 0.7901\n",
            "Epoch 9/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.8427 - acc: 0.7310 - val_loss: 0.6894 - val_acc: 0.7865\n",
            "Epoch 10/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.8454 - acc: 0.7305 - val_loss: 0.6319 - val_acc: 0.8012\n",
            "Epoch 11/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.7947 - acc: 0.7516 - val_loss: 0.7118 - val_acc: 0.7840\n",
            "Epoch 12/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.7806 - acc: 0.7472 - val_loss: 0.6444 - val_acc: 0.7880\n",
            "Epoch 13/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.7575 - acc: 0.7591 - val_loss: 0.5864 - val_acc: 0.8098\n",
            "Epoch 14/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.7400 - acc: 0.7643 - val_loss: 0.5746 - val_acc: 0.8180\n",
            "Epoch 15/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.7343 - acc: 0.7606 - val_loss: 0.5773 - val_acc: 0.8103\n",
            "Epoch 16/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.7303 - acc: 0.7640 - val_loss: 0.5776 - val_acc: 0.8109\n",
            "Epoch 17/500\n",
            "1109/1109 [==============================] - 23s 21ms/step - loss: 0.6992 - acc: 0.7778 - val_loss: 0.5162 - val_acc: 0.8362\n",
            "Epoch 18/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6736 - acc: 0.7805 - val_loss: 0.5911 - val_acc: 0.8129\n",
            "Epoch 19/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6677 - acc: 0.7869 - val_loss: 0.5007 - val_acc: 0.8392\n",
            "Epoch 20/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6533 - acc: 0.7908 - val_loss: 0.4985 - val_acc: 0.8423\n",
            "Epoch 21/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6442 - acc: 0.7872 - val_loss: 0.4947 - val_acc: 0.8403\n",
            "Epoch 22/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6655 - acc: 0.7831 - val_loss: 0.5585 - val_acc: 0.8245\n",
            "Epoch 23/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6567 - acc: 0.7862 - val_loss: 0.4999 - val_acc: 0.8403\n",
            "Epoch 24/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6241 - acc: 0.7974 - val_loss: 0.5148 - val_acc: 0.8372\n",
            "Epoch 25/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6221 - acc: 0.7944 - val_loss: 0.5401 - val_acc: 0.8387\n",
            "Epoch 26/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6196 - acc: 0.7997 - val_loss: 0.5903 - val_acc: 0.8357\n",
            "Epoch 27/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6185 - acc: 0.7992 - val_loss: 0.4856 - val_acc: 0.8474\n",
            "Epoch 28/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.5877 - acc: 0.8079 - val_loss: 0.4753 - val_acc: 0.8433\n",
            "Epoch 29/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6037 - acc: 0.8012 - val_loss: 0.4976 - val_acc: 0.8398\n",
            "Epoch 30/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6019 - acc: 0.8032 - val_loss: 0.5200 - val_acc: 0.8316\n",
            "Epoch 31/500\n",
            "1109/1109 [==============================] - 23s 21ms/step - loss: 0.5765 - acc: 0.8108 - val_loss: 0.4659 - val_acc: 0.8504\n",
            "Epoch 32/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5745 - acc: 0.8199 - val_loss: 0.4846 - val_acc: 0.8448\n",
            "Epoch 33/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5849 - acc: 0.8080 - val_loss: 0.5191 - val_acc: 0.8377\n",
            "Epoch 34/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.5588 - acc: 0.8182 - val_loss: 0.5883 - val_acc: 0.8144\n",
            "Epoch 35/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.5721 - acc: 0.8143 - val_loss: 0.5035 - val_acc: 0.8479\n",
            "Epoch 36/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5654 - acc: 0.8143 - val_loss: 0.4927 - val_acc: 0.8413\n",
            "Epoch 37/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5526 - acc: 0.8160 - val_loss: 0.4651 - val_acc: 0.8387\n",
            "Epoch 38/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5550 - acc: 0.8137 - val_loss: 0.4657 - val_acc: 0.8479\n",
            "Epoch 39/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.5446 - acc: 0.8213 - val_loss: 0.4418 - val_acc: 0.8540\n",
            "Epoch 40/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.5326 - acc: 0.8257 - val_loss: 0.4639 - val_acc: 0.8474\n",
            "Epoch 41/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5282 - acc: 0.8254 - val_loss: 0.4901 - val_acc: 0.8453\n",
            "Epoch 42/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5435 - acc: 0.8247 - val_loss: 0.4761 - val_acc: 0.8387\n",
            "Epoch 43/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.5361 - acc: 0.8218 - val_loss: 0.4463 - val_acc: 0.8555\n",
            "Epoch 44/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.5258 - acc: 0.8227 - val_loss: 0.4431 - val_acc: 0.8570\n",
            "Epoch 45/500\n",
            "1109/1109 [==============================] - 23s 21ms/step - loss: 0.5289 - acc: 0.8291 - val_loss: 0.4175 - val_acc: 0.8697\n",
            "Epoch 46/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.5209 - acc: 0.8319 - val_loss: 0.4630 - val_acc: 0.8489\n",
            "Epoch 47/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.5084 - acc: 0.8354 - val_loss: 0.4303 - val_acc: 0.8636\n",
            "Epoch 48/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.5258 - acc: 0.8290 - val_loss: 0.4314 - val_acc: 0.8605\n",
            "Epoch 49/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5001 - acc: 0.8384 - val_loss: 0.4406 - val_acc: 0.8616\n",
            "Epoch 50/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5226 - acc: 0.8277 - val_loss: 0.4381 - val_acc: 0.8621\n",
            "Epoch 51/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5068 - acc: 0.8306 - val_loss: 0.4385 - val_acc: 0.8555\n",
            "Epoch 52/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5195 - acc: 0.8290 - val_loss: 0.4246 - val_acc: 0.8636\n",
            "Epoch 53/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4988 - acc: 0.8382 - val_loss: 0.4050 - val_acc: 0.8707\n",
            "Epoch 54/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5018 - acc: 0.8371 - val_loss: 0.4267 - val_acc: 0.8646\n",
            "Epoch 55/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5020 - acc: 0.8329 - val_loss: 0.4197 - val_acc: 0.8631\n",
            "Epoch 56/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4810 - acc: 0.8383 - val_loss: 0.4415 - val_acc: 0.8565\n",
            "Epoch 57/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4921 - acc: 0.8345 - val_loss: 0.4485 - val_acc: 0.8580\n",
            "Epoch 58/500\n",
            "1109/1109 [==============================] - 23s 21ms/step - loss: 0.4797 - acc: 0.8428 - val_loss: 0.4373 - val_acc: 0.8570\n",
            "Epoch 59/500\n",
            "1109/1109 [==============================] - 23s 21ms/step - loss: 0.4907 - acc: 0.8375 - val_loss: 0.4336 - val_acc: 0.8605\n",
            "Epoch 60/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.4792 - acc: 0.8400 - val_loss: 0.4588 - val_acc: 0.8484\n",
            "Epoch 61/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.4817 - acc: 0.8406 - val_loss: 0.4309 - val_acc: 0.8646\n",
            "Epoch 62/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.4739 - acc: 0.8438 - val_loss: 0.4187 - val_acc: 0.8676\n",
            "Epoch 63/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.4590 - acc: 0.8466 - val_loss: 0.4760 - val_acc: 0.8494\n",
            "Epoch 64/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.4296 - acc: 0.8509 - val_loss: 0.3860 - val_acc: 0.8742\n",
            "Epoch 65/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.3954 - acc: 0.8681 - val_loss: 0.3807 - val_acc: 0.8768\n",
            "Epoch 66/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.3953 - acc: 0.8712 - val_loss: 0.3724 - val_acc: 0.8783\n",
            "Epoch 67/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.3779 - acc: 0.8743 - val_loss: 0.3717 - val_acc: 0.8788\n",
            "Epoch 68/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.3969 - acc: 0.8618 - val_loss: 0.3745 - val_acc: 0.8824\n",
            "Epoch 69/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.3906 - acc: 0.8652 - val_loss: 0.3714 - val_acc: 0.8818\n",
            "Epoch 70/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.3989 - acc: 0.8686 - val_loss: 0.3712 - val_acc: 0.8808\n",
            "Epoch 71/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.3603 - acc: 0.8817 - val_loss: 0.3854 - val_acc: 0.8768\n",
            "Epoch 72/500\n",
            "1109/1109 [==============================] - 23s 21ms/step - loss: 0.3842 - acc: 0.8713 - val_loss: 0.3743 - val_acc: 0.8793\n",
            "Epoch 73/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.3621 - acc: 0.8770 - val_loss: 0.3512 - val_acc: 0.8813\n",
            "Epoch 74/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.3701 - acc: 0.8736 - val_loss: 0.3630 - val_acc: 0.8793\n",
            "Epoch 75/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.3578 - acc: 0.8790 - val_loss: 0.3565 - val_acc: 0.8803\n",
            "Epoch 76/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.3721 - acc: 0.8725 - val_loss: 0.3571 - val_acc: 0.8854\n",
            "Epoch 77/500\n",
            "1109/1109 [==============================] - 23s 21ms/step - loss: 0.3773 - acc: 0.8732 - val_loss: 0.3562 - val_acc: 0.8869\n",
            "Epoch 78/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.3555 - acc: 0.8781 - val_loss: 0.3585 - val_acc: 0.8854\n",
            "Epoch 79/500\n",
            "1109/1109 [==============================] - 23s 21ms/step - loss: 0.3704 - acc: 0.8730 - val_loss: 0.3522 - val_acc: 0.8834\n",
            "Epoch 80/500\n",
            "1109/1109 [==============================] - 23s 21ms/step - loss: 0.3618 - acc: 0.8763 - val_loss: 0.3603 - val_acc: 0.8829\n",
            "Epoch 81/500\n",
            "1109/1109 [==============================] - 23s 21ms/step - loss: 0.3702 - acc: 0.8770 - val_loss: 0.3639 - val_acc: 0.8808\n",
            "Epoch 82/500\n",
            "1109/1109 [==============================] - 23s 21ms/step - loss: 0.3454 - acc: 0.8844 - val_loss: 0.3565 - val_acc: 0.8818\n",
            "Epoch 83/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.3482 - acc: 0.8834 - val_loss: 0.3586 - val_acc: 0.8808\n",
            "Epoch 84/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.3468 - acc: 0.8806 - val_loss: 0.3550 - val_acc: 0.8803\n",
            "Epoch 85/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3449 - acc: 0.8814 - val_loss: 0.3530 - val_acc: 0.8773\n",
            "Epoch 86/500\n",
            "1109/1109 [==============================] - 23s 21ms/step - loss: 0.3300 - acc: 0.8874 - val_loss: 0.3522 - val_acc: 0.8813\n",
            "Epoch 87/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3419 - acc: 0.8822 - val_loss: 0.3536 - val_acc: 0.8813\n",
            "Epoch 88/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3382 - acc: 0.8859 - val_loss: 0.3485 - val_acc: 0.8818\n",
            "Epoch 89/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3304 - acc: 0.8867 - val_loss: 0.3520 - val_acc: 0.8834\n",
            "Epoch 90/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3320 - acc: 0.8856 - val_loss: 0.3505 - val_acc: 0.8844\n",
            "Epoch 91/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3442 - acc: 0.8753 - val_loss: 0.3483 - val_acc: 0.8869\n",
            "Epoch 92/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3381 - acc: 0.8826 - val_loss: 0.3496 - val_acc: 0.8854\n",
            "Epoch 93/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3336 - acc: 0.8880 - val_loss: 0.3498 - val_acc: 0.8844\n",
            "Epoch 94/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3339 - acc: 0.8839 - val_loss: 0.3461 - val_acc: 0.8849\n",
            "Epoch 95/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3380 - acc: 0.8858 - val_loss: 0.3490 - val_acc: 0.8813\n",
            "Epoch 96/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3333 - acc: 0.8866 - val_loss: 0.3486 - val_acc: 0.8844\n",
            "Epoch 97/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3411 - acc: 0.8823 - val_loss: 0.3480 - val_acc: 0.8839\n",
            "Epoch 98/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3341 - acc: 0.8853 - val_loss: 0.3493 - val_acc: 0.8844\n",
            "Epoch 99/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3245 - acc: 0.8886 - val_loss: 0.3496 - val_acc: 0.8844\n",
            "Epoch 100/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.3373 - acc: 0.8872 - val_loss: 0.3481 - val_acc: 0.8869\n",
            "Epoch 101/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3308 - acc: 0.8845 - val_loss: 0.3480 - val_acc: 0.8844\n",
            "Epoch 102/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3129 - acc: 0.8894 - val_loss: 0.3508 - val_acc: 0.8834\n",
            "Epoch 103/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3251 - acc: 0.8902 - val_loss: 0.3518 - val_acc: 0.8813\n",
            "Epoch 104/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3210 - acc: 0.8880 - val_loss: 0.3519 - val_acc: 0.8818\n",
            "Epoch 105/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3329 - acc: 0.8872 - val_loss: 0.3494 - val_acc: 0.8818\n",
            "Epoch 106/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3318 - acc: 0.8834 - val_loss: 0.3501 - val_acc: 0.8844\n",
            "Epoch 107/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3194 - acc: 0.8906 - val_loss: 0.3468 - val_acc: 0.8839\n",
            "Epoch 108/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3190 - acc: 0.8918 - val_loss: 0.3516 - val_acc: 0.8854\n",
            "Epoch 109/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3218 - acc: 0.8916 - val_loss: 0.3470 - val_acc: 0.8839\n",
            "Epoch 110/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3408 - acc: 0.8811 - val_loss: 0.3484 - val_acc: 0.8844\n",
            "Epoch 111/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3250 - acc: 0.8906 - val_loss: 0.3472 - val_acc: 0.8879\n",
            "Epoch 112/500\n",
            "1109/1109 [==============================] - 22s 19ms/step - loss: 0.3341 - acc: 0.8898 - val_loss: 0.3492 - val_acc: 0.8844\n",
            "Epoch 113/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3369 - acc: 0.8859 - val_loss: 0.3462 - val_acc: 0.8849\n",
            "Epoch 114/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.3200 - acc: 0.8903 - val_loss: 0.3476 - val_acc: 0.8854\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 0.3620 - acc: 0.8832\n",
            "loss :  0.361981064081192\n",
            "acc :  0.8831676244735718\n",
            "\n",
            "** Kfold 4 번째 실행 중 **\n",
            "(17740, 56, 56, 3) (2816, 56, 56, 3) (1972, 56, 56, 3)\n",
            "(17740,) (2816,) (1972,)\n",
            "Epoch 1/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 2.4601 - acc: 0.3058 - val_loss: 1.4343 - val_acc: 0.5695\n",
            "Epoch 2/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 1.4162 - acc: 0.5614 - val_loss: 1.8068 - val_acc: 0.5816\n",
            "Epoch 3/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 1.2037 - acc: 0.6221 - val_loss: 0.8966 - val_acc: 0.7221\n",
            "Epoch 4/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 1.1195 - acc: 0.6511 - val_loss: 0.8245 - val_acc: 0.7394\n",
            "Epoch 5/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 1.0382 - acc: 0.6724 - val_loss: 0.7677 - val_acc: 0.7642\n",
            "Epoch 6/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.9784 - acc: 0.6907 - val_loss: 0.7896 - val_acc: 0.7505\n",
            "Epoch 7/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.9411 - acc: 0.7036 - val_loss: 0.7370 - val_acc: 0.7733\n",
            "Epoch 8/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.8983 - acc: 0.7152 - val_loss: 0.8807 - val_acc: 0.7241\n",
            "Epoch 9/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.8798 - acc: 0.7196 - val_loss: 0.6646 - val_acc: 0.7880\n",
            "Epoch 10/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.8295 - acc: 0.7377 - val_loss: 0.6294 - val_acc: 0.7961\n",
            "Epoch 11/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.8157 - acc: 0.7399 - val_loss: 0.6226 - val_acc: 0.8134\n",
            "Epoch 12/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.7958 - acc: 0.7443 - val_loss: 0.6361 - val_acc: 0.8032\n",
            "Epoch 13/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.7694 - acc: 0.7548 - val_loss: 0.5880 - val_acc: 0.8271\n",
            "Epoch 14/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.7715 - acc: 0.7592 - val_loss: 0.6612 - val_acc: 0.7972\n",
            "Epoch 15/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.7586 - acc: 0.7541 - val_loss: 0.5701 - val_acc: 0.8185\n",
            "Epoch 16/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.7382 - acc: 0.7606 - val_loss: 0.6537 - val_acc: 0.7951\n",
            "Epoch 17/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.7270 - acc: 0.7667 - val_loss: 0.6166 - val_acc: 0.7992\n",
            "Epoch 18/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.7036 - acc: 0.7701 - val_loss: 0.5678 - val_acc: 0.8225\n",
            "Epoch 19/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6941 - acc: 0.7825 - val_loss: 0.5399 - val_acc: 0.8433\n",
            "Epoch 20/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6696 - acc: 0.7802 - val_loss: 0.5056 - val_acc: 0.8423\n",
            "Epoch 21/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6594 - acc: 0.7884 - val_loss: 0.5613 - val_acc: 0.8266\n",
            "Epoch 22/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6710 - acc: 0.7845 - val_loss: 0.5423 - val_acc: 0.8271\n",
            "Epoch 23/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6704 - acc: 0.7860 - val_loss: 0.5576 - val_acc: 0.8311\n",
            "Epoch 24/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6413 - acc: 0.7897 - val_loss: 0.5250 - val_acc: 0.8306\n",
            "Epoch 25/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6434 - acc: 0.7952 - val_loss: 0.5063 - val_acc: 0.8413\n",
            "Epoch 26/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6542 - acc: 0.7898 - val_loss: 0.5022 - val_acc: 0.8448\n",
            "Epoch 27/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6352 - acc: 0.7999 - val_loss: 0.5081 - val_acc: 0.8337\n",
            "Epoch 28/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6235 - acc: 0.7943 - val_loss: 0.5320 - val_acc: 0.8377\n",
            "Epoch 29/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6265 - acc: 0.7940 - val_loss: 0.4710 - val_acc: 0.8524\n",
            "Epoch 30/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.6092 - acc: 0.8040 - val_loss: 0.4735 - val_acc: 0.8479\n",
            "Epoch 31/500\n",
            "1109/1109 [==============================] - 21s 19ms/step - loss: 0.6181 - acc: 0.8011 - val_loss: 0.4923 - val_acc: 0.8463\n",
            "Epoch 32/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5955 - acc: 0.8070 - val_loss: 0.4562 - val_acc: 0.8514\n",
            "Epoch 33/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5868 - acc: 0.8035 - val_loss: 0.4464 - val_acc: 0.8555\n",
            "Epoch 34/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5920 - acc: 0.8110 - val_loss: 0.4748 - val_acc: 0.8504\n",
            "Epoch 35/500\n",
            "1109/1109 [==============================] - 22s 19ms/step - loss: 0.5849 - acc: 0.8132 - val_loss: 0.4512 - val_acc: 0.8600\n",
            "Epoch 36/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5628 - acc: 0.8127 - val_loss: 0.4720 - val_acc: 0.8484\n",
            "Epoch 37/500\n",
            "1109/1109 [==============================] - 21s 19ms/step - loss: 0.5769 - acc: 0.8101 - val_loss: 0.4658 - val_acc: 0.8600\n",
            "Epoch 38/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5573 - acc: 0.8178 - val_loss: 0.4735 - val_acc: 0.8504\n",
            "Epoch 39/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5573 - acc: 0.8184 - val_loss: 0.4494 - val_acc: 0.8545\n",
            "Epoch 40/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5582 - acc: 0.8182 - val_loss: 0.4652 - val_acc: 0.8474\n",
            "Epoch 41/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5443 - acc: 0.8176 - val_loss: 0.4611 - val_acc: 0.8555\n",
            "Epoch 42/500\n",
            "1109/1109 [==============================] - 23s 21ms/step - loss: 0.5579 - acc: 0.8154 - val_loss: 0.4230 - val_acc: 0.8646\n",
            "Epoch 43/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5276 - acc: 0.8254 - val_loss: 0.4582 - val_acc: 0.8560\n",
            "Epoch 44/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5471 - acc: 0.8189 - val_loss: 0.4818 - val_acc: 0.8443\n",
            "Epoch 45/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5266 - acc: 0.8306 - val_loss: 0.4223 - val_acc: 0.8732\n",
            "Epoch 46/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5423 - acc: 0.8217 - val_loss: 0.4309 - val_acc: 0.8651\n",
            "Epoch 47/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.5197 - acc: 0.8296 - val_loss: 0.4534 - val_acc: 0.8514\n",
            "Epoch 48/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5143 - acc: 0.8300 - val_loss: 0.4676 - val_acc: 0.8519\n",
            "Epoch 49/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5205 - acc: 0.8288 - val_loss: 0.4430 - val_acc: 0.8646\n",
            "Epoch 50/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.5078 - acc: 0.8330 - val_loss: 0.4721 - val_acc: 0.8534\n",
            "Epoch 51/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.5189 - acc: 0.8263 - val_loss: 0.4196 - val_acc: 0.8687\n",
            "Epoch 52/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.5336 - acc: 0.8226 - val_loss: 0.4011 - val_acc: 0.8742\n",
            "Epoch 53/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.5043 - acc: 0.8308 - val_loss: 0.4539 - val_acc: 0.8621\n",
            "Epoch 54/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.5251 - acc: 0.8243 - val_loss: 0.4322 - val_acc: 0.8626\n",
            "Epoch 55/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.5082 - acc: 0.8265 - val_loss: 0.4150 - val_acc: 0.8727\n",
            "Epoch 56/500\n",
            "1109/1109 [==============================] - 23s 21ms/step - loss: 0.5061 - acc: 0.8335 - val_loss: 0.4311 - val_acc: 0.8702\n",
            "Epoch 57/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.4888 - acc: 0.8318 - val_loss: 0.4266 - val_acc: 0.8732\n",
            "Epoch 58/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4924 - acc: 0.8368 - val_loss: 0.4936 - val_acc: 0.8656\n",
            "Epoch 59/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.4871 - acc: 0.8359 - val_loss: 0.4299 - val_acc: 0.8621\n",
            "Epoch 60/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.4871 - acc: 0.8400 - val_loss: 0.4576 - val_acc: 0.8646\n",
            "Epoch 61/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.4745 - acc: 0.8377 - val_loss: 0.4473 - val_acc: 0.8687\n",
            "Epoch 62/500\n",
            "1109/1109 [==============================] - 22s 20ms/step - loss: 0.4968 - acc: 0.8355 - val_loss: 0.4771 - val_acc: 0.8600\n",
            "Epoch 63/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.4636 - acc: 0.8453 - val_loss: 0.4007 - val_acc: 0.8753\n",
            "Epoch 64/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.4287 - acc: 0.8527 - val_loss: 0.3901 - val_acc: 0.8818\n",
            "Epoch 65/500\n",
            "1109/1109 [==============================] - 23s 21ms/step - loss: 0.4225 - acc: 0.8562 - val_loss: 0.3773 - val_acc: 0.8813\n",
            "Epoch 66/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.4043 - acc: 0.8654 - val_loss: 0.3871 - val_acc: 0.8844\n",
            "Epoch 67/500\n",
            "1109/1109 [==============================] - 23s 20ms/step - loss: 0.4088 - acc: 0.8639 - val_loss: 0.3772 - val_acc: 0.8884\n",
            "Epoch 68/500\n",
            "1085/1109 [============================>.] - ETA: 0s - loss: 0.4035 - acc: 0.8626"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sugm5dAyT4GD"
      },
      "source": [
        "# 잘 예측하는지 확인 \r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.image as img\r\n",
        "from glob import glob \r\n",
        "\r\n",
        "# submission\r\n",
        "sub = pd.read_csv('/content/MyDrive/MyDrive/Colab/DACON_vision2/sample_submission.csv')\r\n",
        "# print(sub.head())\r\n",
        "\r\n",
        "# model = load_model('/content/MyDrive/MyDrive/Colab/DACON_vision2/cp/vision_0226_1_vison1_0.3941.hdf5') # <<-- 여기에 데이콘2 테스트 데이터를 넣어서 숫자를 예측한다.\r\n",
        "\r\n",
        "n = 50000\r\n",
        "row = 0\r\n",
        "for i in range(5000) :\r\n",
        "    print(\"start >>> \", n)\r\n",
        "    test_img=glob(f'/content/MyDrive/MyDrive/Colab/DACON_vision2/contour/{n}_*.png')\r\n",
        "    print(len(test_img))\r\n",
        "\r\n",
        "    predict_list = []\r\n",
        "\r\n",
        "    for img in test_img :\r\n",
        "        pred_img = cv2.imread(img) # \r\n",
        "\r\n",
        "        # print(pred_img.shape)   # (64, 64, 3)\r\n",
        "        plt.imshow(pred_img)\r\n",
        "        cv2.waitKey(0)\r\n",
        "\r\n",
        "        pred_img = pred_img.astype('float32')\r\n",
        "        pred_img = cv2.resize(pred_img, (56,56))\r\n",
        "        # print(pred_img.shape)   # (56, 56)\r\n",
        "\r\n",
        "        pred_img = pred_img.reshape(1, pred_img.shape[0], pred_img.shape[1], pred_img.shape[2])/255.\r\n",
        "        # print(pred_img.shape)   # (1, 56, 56, 3)\r\n",
        "        pred_generator = idg2.flow(pred_img, shuffle=False)\r\n",
        "\r\n",
        "        result = model.predict_generator(pred_generator, verbose=True)\r\n",
        "        print(result.max())\r\n",
        "        if result.max() < 0.6 : # 최대 예측값이 60%를 넘지 않는다면 이상한 문자이므로 패쓰한다.\r\n",
        "            pass\r\n",
        "        else :\r\n",
        "            result_max = result.argmax(1)[0]\r\n",
        "            print(result_max) \r\n",
        "            predict_list.append(result_max)\r\n",
        "\r\n",
        "    # 중복값 제거하기 위해서 집합으로 만들었다가 리스트로 변환\r\n",
        "    predict_set = set(predict_list)\r\n",
        "    predict_list = list(predict_set)\r\n",
        "    print(predict_list)\r\n",
        "\r\n",
        "    # submission 형태로 만들기\r\n",
        "    result = np.zeros((1,26), dtype=np.int8)\r\n",
        "    # print(result)\r\n",
        "\r\n",
        "    for idx in predict_list :\r\n",
        "        result[0][idx] = 1\r\n",
        "    print(result)\r\n",
        "\r\n",
        "    sub.iloc[row][1:] = result[0]\r\n",
        "    sub.to_csv('/content/MyDrive/MyDrive/Colab/DACON_vision2/sub_0301_1.csv', index=False)\r\n",
        "    print(sub.head())\r\n",
        "\r\n",
        "    n += 1\r\n",
        "    row += 1\r\n",
        "\r\n",
        "print(\"==Done==\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}